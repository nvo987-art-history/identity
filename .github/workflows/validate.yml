name: ULTRA PRO Site Validation (AI + SEO + Security + Performance)

on:
  push:
    branches: [ main ]
  pull_request:

jobs:
  validate:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

# =====================================================
# INSTALL TOOLS
# =====================================================

      - name: Install packages
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            tidy \
            libxml2-utils \
            jq \
            poppler-utils \
            linkchecker \
            wget \
            curl \
            nodejs npm

          npm install -g lighthouse

# =====================================================
# HTML VALIDATION
# =====================================================

      - name: Validate HTML
        run: |
          for f in $(find . -name "*.html"); do
            echo "HTML: $f"
            tidy -qe "$f"
          done

# =====================================================
# XML / SITEMAP
# =====================================================

      - name: Validate XML
        run: |
          for f in $(find . -name "*.xml"); do
            xmllint --noout "$f"
          done

# =====================================================
# JSON / API
# =====================================================

      - name: Validate JSON / API
        run: |
          for f in $(find . -name "*.json"); do
            jq empty "$f"
          done

# =====================================================
# REQUIRED FILES
# =====================================================

      - name: Check required files
        run: |
          test -f robots.txt
          test -f llms.txt
          test -f sitemap.xml
          test -f index.html

# =====================================================
# SCHEMA.ORG / JSON-LD
# =====================================================

      - name: Check schema.org presence
        run: |
          if ! grep -R "schema.org" .; then
            echo "Missing schema.org structured data"
            exit 1
          fi

# =====================================================
# ROBOTS + LLMS FORMAT
# =====================================================

      - name: Validate robots/llms format
        run: |
          grep -E "User-Agent|Allow|Disallow" robots.txt
          grep -E "User-Agent|Allow|Disallow" llms.txt

# =====================================================
# BROKEN LINKS
# =====================================================

      - name: Check broken links
        run: |
          linkchecker index.html --check-extern || true

# =====================================================
# PDF â†’ TEXT (AI readability)
# =====================================================

      - name: Check PDFs readable
        run: |
          for f in $(find . -name "*.pdf"); do
            pdftotext "$f" - > /dev/null
          done

# =====================================================
# DUPLICATE FILENAMES
# =====================================================

      - name: Check duplicates
run: |
    dup=$(find . -path ./.git -prune -o -type f -exec basename {} \; | sort | uniq -d)
    if [ ! -z "$dup" ]; then
      echo "Duplicate filenames:"
      echo "$dup"
      exit 1
    fi

# =====================================================
# LARGE FILES LIMIT
# =====================================================

      - name: Check file sizes
        run: |
          big=$(find . -type f -size +10M)
          if [ ! -z "$big" ]; then
            echo "Too large files:"
            echo "$big"
            exit 1
          fi

# =====================================================
# SEO META TAGS
# =====================================================

      - name: Check SEO meta tags
        run: |
          grep -R "<title>" .
          grep -R "meta name=\"description\"" .

# =====================================================
# SECURITY HEADERS
# =====================================================

      - name: Security headers test
        run: |
          curl -Is https://identity.nvo987.us | grep -E \
          "Strict-Transport|Content-Security|X-Frame|X-Content|Referrer|Permissions"

# =====================================================
# LIGHTHOUSE PERFORMANCE + SEO + ACCESSIBILITY
# =====================================================

      - name: Lighthouse audit
        run: |
          lighthouse https://identity.nvo987.us \
            --chrome-flags="--headless" \
            --output html \
            --output-path ./lighthouse.html

# =====================================================
# SITEMAP URL CHECK
# =====================================================

      - name: Test sitemap URLs
        run: |
          urls=$(grep -oP '(?<=<loc>).*?(?=</loc>)' sitemap.xml)
          for u in $urls; do
            curl -s -o /dev/null -w "%{http_code} $u\n" $u
          done

# =====================================================
# SHA256 CHECKSUM GENERATION
# =====================================================

      - name: Generate SHA256 checksums
        run: |
          find . -type f -not -path "./.git/*" -exec sha256sum {} \; > checksums.txt

# =====================================================
# AI DATASET EXPORT (txt only)
# =====================================================

      - name: Generate AI dataset
        run: |
          find . -name "*.txt" -exec cat {} \; > ai-dataset.txt

# =====================================================
# UPLOAD ARTIFACTS
# =====================================================

      - uses: actions/upload-artifact@v4
        with:
          name: reports
          path: |
            checksums.txt
            lighthouse.html
            ai-dataset.txt
