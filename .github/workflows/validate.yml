name: Validate site

on:
  push:
  pull_request:

jobs:
  validate:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # -----------------------
      # Install tools
      # -----------------------
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq libxml2-utils curl poppler-utils

      # -----------------------
      # Validate JSON / API
      # -----------------------
      - name: Validate JSON files
        run: |
          find . -name "*.json" -type f -print0 | while IFS= read -r -d '' f; do
            echo "Checking $f"
            jq empty "$f" || exit 1
          done

      # -----------------------
      # Validate XML
      # -----------------------
      - name: Validate XML files
        run: |
          find . -name "*.xml" -type f -print0 | while IFS= read -r -d '' f; do
            echo "Checking $f"
            xmllint --noout "$f" || exit 1
          done

      # -----------------------
      # Validate HTML
      # -----------------------
      - name: Validate HTML files
        run: |
          find . -name "*.html" -type f -print0 | while IFS= read -r -d '' f; do
            echo "Checking $f"
            xmllint --html --noout "$f" || true
          done

      # -----------------------
      # Required files
      # -----------------------
      - name: Check required files
        run: |
          test -f robots.txt || echo "robots.txt missing"
          test -f llms.txt || echo "llms.txt missing"
          test -f sitemap.xml || echo "sitemap.xml missing"

      # -----------------------
      # Schema.org presence
      # -----------------------
      - name: Check schema.org presence
        run: |
          grep -r "schema.org" . || echo "No schema.org found (warning)"

      # -----------------------
      # Validate robots / llms
      # -----------------------
      - name: Validate robots/llms format
        run: |
          grep -E "User-Agent:" robots.txt llms.txt || echo "No User-Agent found (warning)"

      # -----------------------
      # Check broken links (SAFE)
      # -----------------------
      - name: Check broken links
        run: |
          set +e
          urls=$(grep -rhoE 'https?://[A-Za-z0-9._~:/?#@!$&()*+,;=%-]+' . | sort -u)

          for u in $urls; do
            echo "Testing $u"
            curl -Is --max-time 10 "$u" >/dev/null
          done

          exit 0

      # -----------------------
      # Test sitemap URLs
      # -----------------------
      - name: Test sitemap URLs
        run: |
          if [ -f sitemap.xml ]; then
            urls=$(grep -oP '(?<=<loc>).*?(?=</loc>)' sitemap.xml)
            for u in $urls; do
              echo "Testing $u"
              curl -Is --max-time 10 "$u" >/dev/null
            done
          fi
          exit 0

      # -----------------------
      # Check PDFs readable
      # -----------------------
      - name: Check PDFs readable
        run: |
          find . -name "*.pdf" -type f -print0 | while IFS= read -r -d '' f; do
            echo "Checking $f"
            pdftotext "$f" /dev/null || true
          done

      # -----------------------
      # Generate SHA256
      # -----------------------
      - name: Generate SHA256 checksums
        run: |
          find . -type f -not -path "./.git/*" -exec sha256sum {} \; > checksums.sha256

      # -----------------------
      # Generate AI dataset
      # -----------------------
      - name: Generate AI dataset
        run: |
          mkdir -p ai_dataset
          cp -r *.json *.xml *.txt *.html ai_dataset/ 2>/dev/null || true
          tar -czf ai_dataset.tar.gz ai_dataset

      # -----------------------
      # Upload artifacts
      # -----------------------
      - uses: actions/upload-artifact@v4
        with:
          name: ai-build
          path: |
            checksums.sha256
            ai_dataset.tar.gz
